\documentclass{llncs}

\usepackage[a4paper,includeheadfoot,top=1.65in,bottom=1.65in,left=1.73in,hcentering]{geometry}
\usepackage[pdftex]{graphicx}

% Ezek egyikÈnek bekapcsol·s·val a magyar Èkezetes karakterek
% kˆzvetlen¸l is felhaszn·lhatÛk:
%\usepackage[latin2]{inputenc} 
\usepackage[utf8]{inputenc}

\usepackage[hungarian]{babel}
\selectlanguage{hungarian} 

\usepackage{booktabs}

\begin{document}

\pagestyle{myheadings}
\def\leftmark{{\rm IX. Magyar Sz\'am\'\i t\'og\'epes Nyelv\'eszeti Konferencia}}
\def\rightmark{{\rm Szeged, 2013. január 7-8.}}

\setcounter{page}{3}

\title{\ \break Automatikusan tulajdonnév-annotált korpuszok előállítása a Wikipédiából}
%XXX a címet majd meg kéne változtatni, tényleg elég bénán hangzik magyarul
%Automatikus korpuszépítés tulajdonnév-felismerés céljára
\author{Nemeskey Dávid Márk\inst{1}, Simon Eszter\inst{2}}
\institute{
\inst{}%
MTA SZTAKI \break
1111 Budapest, Lágymányosi utca 11., e-mail:nemeskey@sztaki.mta.hu \break
\and
\inst{}%
MTA Nyelvtudományi Intézet \break
1068 Budapest, Benczúr u. 33., e-mail: simon.eszter@nytud.mta.hu}

\maketitle

\begin{abstract}
A felügyelt gépi tanulási módszerek alkalmazásához nagy méretű annotált korpuszokra van szükség, amelyek előállítása rendkívül emberierőforrás-igényes. Több lehetőség van az annotációs költségek csökkentésére, ezek közül az egyik az automatikus annotálás. Cikkünkben egy nyelvfüggetlen módszert és azzal előállított magyar és angol nyelvű korpuszokat mutatunk be. A korpuszok szövege a Wikipédiából származik, és tulajdonnévi annotálást is tartalmaz. Az automatikus annotáláshoz egy új módszert alkalmaztunk: a DBpedia ontológiai kategóriáit képeztük le a CoNLL névosztályokra. A korpuszok szabadon felhasználhatóak további fejlesztésekhez.
\\[2mm]
{\bf Kulcsszavak:} tulajdonnév-felismerés, korpuszépítés,
automatikus annotáció, Wikipédia
\end{abstract}

\section{Bevezet\'es}

Az automatikus tulajdonnév-felismerés (Named Entity Recognition, NER) a természetes nyelv feldolgozását célzó alkalmazások közül az egyik legnépszerűbb, mivel hatékonyan automatizálható, és eredménye hasznos bemenete különböző magasabb szintű információkinyerő és -feldolgozó rendszereknek. A feladat során strukturálatlan szövegben kell azonosítani és az előre definiált osztályok valamelyikébe besorolni a neveket. A tulajdonnév-felismerés feladata a 6. Message Understanding Conference (MUC) egyik versenykiírásában jelent meg először 1995-ben \cite{MUC6}. Itt három alfeladatot különítettek el: tulajdonneveket (ENAMEX), temporális (TIMEX) és különböző numerikus (NUMEX) kifejezéseket kellett felismerni. A NER-közösségen belül a temporális és a numerikus kifejezések annotálása is elfogadott, de a leginkább vizsgált típusok a személy-, földrajzi és intézménynevek. Ezek mellé vezettek be a CoNLL versenyeken \cite{tksintro2002conll} \cite{conll2003intro} egy negyedik típust, amely az előző háromba nem tartozó egyéb tulajdonneveket foglalja magában. Az azóta eltelt időben ezek az annotációs sémák váltak nemzetközileg elfogadottá. 

A versenyekre épített és aztán közzétett tulajdonnév-annotált korpuszok képezik azokat a sztenderdeket, amelyek összemérhetővé teszik az egyes tulajdonnév-felismerő rendszereket. Ezek a korpuszok meglehetősen korlátozott méretűek és témaspecifikusak. Kellően robusztus tulajdonnév-felismerő rendszerek építéséhez viszont nagyméretű, a téma tekintetében heterogén korpuszokra van szükség. A kézi annotálás rendkívül idő-, erőforrás- és szakértelemigényes feladat, ezért az elmúlt időkben különösen nagy hangsúly került az annotált erőforrások automatikus előállítására. Ennek egy módja, ha már rendelkezésre álló korpuszokat dolgozunk össze; ekkor a különböző annotációs sémák és címkekészletek összeillesztése állít elénk problémákat. Egy másik lehetőség az olyan webes közösségi tartalmak felhasználása, mint például a Wikipédia, a Wiktionary vagy a DBpedia. Megint másik megközelítés az annotáció automatizálása. 

Cikkünkben egy olyan megközelítést mutatunk be, mely ezen lehetőségeket kombinálja: automatikus eszközökkel tulajdonnév-annotált korpuszokat építettünk Wikipédia szócikkekből. Munkánk során új módszert alkalmaztunk: a DBpedia ontológiai kategóriáit képeztük le a CoNLL-névosztályokra. A létrehozott magyar és angol nyelvű korpuszok szabadon felhasználhatóak. 

A cikk a következőképpen épül fel. A \ref{wiki:ner}.~fejezetben bemutatjuk a Wikipédia eddigi felhasználási módjait a tulajdonnév-felismerés területén. A \ref{corpusbuilding}.~fejezetben leírjuk a korpuszépítési módszert, elsősorban a magyar nyelvű adatokra koncentrálva. Az alkalmazott módszer részletes hibaelemzését a \ref{probl}., a korpuszok leírását a \ref{desc}., míg a kiértékelést és az eredményeket a \ref{results}.~fejezet adja. Cikkünket az elért eredmények rövid összefoglalása zárja (\ref{conc}.~fejezet). 


\section{Wikipédia és tulajdonnév-felismerés}
\label{wiki:ner}

A Wikipédia egy többnyelvű, nyílt tartalmú, az internetes közösség által fejlesztett webes világenciklopédia \footnote{http://wikipedia.org}. Jelenlegi XXX számú szócikkével aranybánya a különböző természetesnyelv-feldolgozó fejlesztések számára; használták már többek között jelentésegyértelműsítére, ontológia- és tezauruszépítésre, valamint kérdésmegválaszoló rendszerekhez (további alkalmazási lehetőségekhez lásd \cite{Medelyan:09}). Mivel a Wikipédia címszavak jelentős része tulajdonnév, adja magát a lehetőség, hogy az automatikus tulajdonnév-felismeréshez is felhasználjuk. 

A Wikipédia legkézenfekvőbb alkalmazási módja nagyméretű névlisták előállítása, melyek javítják az általános célú névfelismerők hatékonyságát, felügyelt és felügyelet nélküli módszerek esetében is (pl.~\cite{Toral:06} és \cite{Nadeau:06}), továbbá a névegyértelműsítésben is fontos szerepet játszanak (pl.~\cite{Bunescu:06}). A Wikipédiában található tudás jegyek formájában is beépíthető tulajdonnév-felismerő rendszerekbe: például Kazama és Torisawa \cite{KaTo07} kísérlete azt bizonyítja, hogy a Wikipédia kategóriacímkéinek automatikus kinyerése növeli egy felügyelt névfelismerő rendszer pontosságát. 

A Wikipédia alkalmazására a tulajdonnév-felismerés területén egy másik lehetőség magának a szövegbázisnak a felhasználása. Richman és Schone \cite{Richman:08} kevés erőforrással rendelkező nyelvek Wikipédia szócikkeiből építettek korpuszokat, amelyekben a Wikipédia inherens kategóriastruktúráját használták fel a tulajdonnevek annotálásához. Nothman et al. \cite{Nothman:08} a szócikkek definíciójának első mondatából kiindulva címkézte fel a szövegben belinkelt neveket, így építve automatikusan tulajdonnév-annotált korpuszt. 

Az általunk alkalmazott módszer az említettekétől annyiban tér el, hogy mi a DBpedia ontológiai osztályait képeztük le a sztenderd CoNLL névosztályokra, majd ezeket Wikipédia entitásokhoz kötöttük. Az így létrehozott korpuszokat szabadon elérhetővé tettük. Tudomásunk szerint jelenleg csak egy angol nyelvű automatikusan tulajdonnév-annotált korpusz létezik, amely szabadon felhasználható, a Semantically Annotated Snapshot of the English Wikipedia \cite{Atserias:08}. Bár a névfelismerést a jelenlegi legjobb szabadon hozzáférhető rendszerekkel végezték, azt gondoljuk, hogy a Wikipédia többezer szerkesztőjének döntésein alapuló kategorizálás megbízhatóbb eredményt ad. A Wikipédiából, tekintve a szócikkek nagy számát, kevés erőforrással rendelkező nyelvekre is tudunk kellően nagy méretű korpuszokat építeni, amelyek bemenetül szolgálhatnak névfelismerő rendszerek tanításához és teszteléséhez. Az általunk létrehozott korpusz az első magyar nyelvű automatikusan tulajdonnév-annotált korpusz. 
%XXX ezt kábé mind leírtam a conclusionben is, szóval innen akár ki is lehet venni

\section{Korpuszépítés}
\label{corpusbuilding}

% TODO: lame wording, angol korpusz?
A korpuszépítő algoritmus, hasonlóan Nothman et al.~\cite{Nothman:08} által
leírthoz, a következő lépésekből áll:

\begin{enumerate}
\item a Wikipédia cikkeket entitásosztályokba soroltuk;
\item a cikkeket mondatokra bontottuk;
\item felcímkéztük a tulajdonneveket a szövegben;
\item kiszűrtük a rossz minőségű mondatokat.
\end{enumerate}

Az algoritmus alapjaiban nyelvfüggetlen: bármelyik nyelvre alkalmazható, amely
rendelkezik megfelelő méretű Wikipédiával. Egyedül a harmadik lépés az, ahol
figyelembe kell venni a nyelv, illetve a használt NER konvenció sajátosságait.
Ennek oka, hogy az egyes nyelvek, illetve NER konvenciók eltérnek abban, hogy
mit tekintenek névelemnek: pl.~a \textit{római} szó a Szeged korpuszban nem
számít annak, míg angol megfelelője, a \textit{Roman} a CoNLL annotációs séma
szerint \texttt{Misc} címkét kapna.

A továbbiakban röviden ismertetjük a fenti lépéseket, a magyar nyelvű korpuszra
koncentrálva. Részletes leírás, illetve az angol nyelvű korpuszban felmerülő
problémák kifejtése \cite{simon-nemeskey:2012:NEWS2012}-ben található.

% Argh, de nehéz magyarul írni :)

\subsection{Wikipédia cikkek mint entitások}

A DBpedia nyelve 

\subsection{A cikkek feldolgozása}
\subsection{Tulajdonnevek címkézése}

\subsection{Szűrés}

% TODO: első részt máshova
A korpuszon a minőség javítása érdekében tartalmi és formai szűrést is
végeztünk. Értelemszerűen eldobtunk minden mondatot, ami azonosítatlan típusú
tulajdonnevet tartalmazott. Kiszűrtük továbbá a rossz minőségű, töredék
mondatokat, vagyis azokat, amelyek nem nagybetűvel kezdődnek, és nincs írásjel
a végükön.

Bár Nothman az első feladatot gépi tanulással oldotta meg, mi a nagyobb
pontosság érdekében a DBpedia~\cite{Bizer:09} tudásbázis alapján osztályoztuk az
entitásokat. A tulajdonneveket Wikipédia kereszthivatkozások segítségével azonosítottuk.
Minden olyan mondatot, ahol ismeretlen név fordult elő, eldobtunk.

\section{Problémás esetek, hibaelemzés}
\label{probl}

A magyar Wikipédia korpusz gépi annotálását kézzel ellenőriztük a korpusz egy kis részén. A 19 milliós teljes korpuszt vettük alapul. Ebből véletlenszerű mondatválogatással csináltunk egy kisebb korpuszt, amely kb.~19000 tokent tartalmaz. Ezt kézzel felannotáltuk, és összehasonlítottuk a kézi és a gépi annotálás eredményét. A következő tipikus hibák rajzolódtak ki. 

Bizonyos esetekben a név környezetében szereplő értelmező szerepű nyelvi egység is a névvel együtt annotálva lett. Ennek az az oka, hogy maga a Wikipédia címszó is tartalmazza ezt a szót, mely leszűkíti a név referenciáját, pl.~\textit{ókori Róma, magyar Wikipédia}. Emberekre utaló linkek esetében ezek nagyrészt rangjelzők, pl.~\textit{Szent István király, Anna brit királynő}. 
%Ez azért marad benne, mert a magyar List of titles stopword listánk nincs?

Egy másik tipikus hibaforrás az automatikus tokenizálás és mondatra bontás. Sok esetben a rövidítést tartalmazó név (pl.~\textit{Warner Bros.}) utolsó eleme, vagyis a pont mondatvégi írásjelként értelmeződik, így nem annotálódik a névvel együtt. Máskor a mondatrabontás során a szövegközbeni link szétszakad, így a maradék elem nem kapja meg a megfelelő címkét. Ezenkívül rengeteg töredékes mondat maradt a szövegben, amelyeket egy erős szűrővel utólag is ki lehet szűrni, pl.~ha minden olyan mondatszerű egységet kidobunk, amelyben nincs ragozott ige. Ezzel persze azok is kiesnek, amelyek szabályos jelen idejű, kijelentő módú, létigét (nem) tartalmazó mondatok. 

Tipikus jelenség a magyarban, amikor egy név összetétel eleme lesz, pl.~\textit{Bizánc-ellenes}. Ilyen esetekben a köznév az összetétel alaptagja, vagyis az határozza meg a referenciát. A referenciaváltozást természetesen a címkézés változásának kell követnie, ami viszont nem, vagy nehezen kezelhető automatikusan, mivel nagyjából bármilyen köznév kapcsolódhat névhez. A helyzetet bonyolítja az is, hogy a mozaikszavakhoz, rövidítésekhez, valamint nem ejtett magánhangzóra végződő idegen nevekhez is kötőjellel kapcsoljuk a toldalékokat, amelynek a felszíni szerkezete nagyon hasonlít az összetételekéhez. Ennek a problémának a megoldása még további vizsgálatokat követel. 

A felsorolt problémás esetek ellenére összességében azt mondhatjuk, hogy a magyar Wikipédia korpusz annotálási pontossága közelíti a gold standard korpuszokét. %na ide jöhetnek majd pontos adatok 

\section{A korpuszok leírása}
\label{desc}

A korpuszokat Creative Commons Attribution-Sharealike 3.0 licensz alatt publikáltuk, vagyis ugyanolyan feltételekkel adjuk tovább, ahogy a Wikipédiából letöltöttük. Szabadon elérhetőek a \texttt{http://hlt.sztaki.hu} oldalon keresztül, valamint a META-SHARE tárhelyről (http://www.meta-net.eu/). (A META-SHARE célja egy nyílt rendszer létrehozása, amely lehetővé teszi a nyelvi erőforrások megosztását; létrehozója a META-NET, az Európai Bizottság által alapított kiválósági hálózat.) 

A fájlok ún.~\emph{multitag} formátumban vannak, amelyben a tartalmas sorok tabulátorral vannak elválasztva. Az első oszlop tartalmazza magukat a szövegszavakat, az egyes oszlopokban pedig a különböző szintű annotációk találhatók. A mondathatárokat üres sorok jelölik. A névcímkéken kívül minden token mellett szerepel a töve és a hozzá tartozó teljes morfológiai elemzése KR-kódokkal. Két további oszlopban közöljük, hogy sima szöveg vagy Wikipédia link-e az adott token, és ha utóbbi, akkor melyik szócikkre utal. 

\section{Kiértékelés}
\label{results}

Az automatikusan generált korpuszok nyilvánvaló előnyei mellett azonban megvan az a hátrányuk, hogy nem használhatók gold standard adatként. Kiértékelésünkben megmutatjuk, hogy a létrehozott silver standard adathalmazok viszont kiválóan használhatók a tulajdonnév-felismerés teljesítményének növelésére több módon is. 

A kiértékeléshez Varga és Simon \cite{Varga} tulajdonnév-felismerő rendszerét használtuk. A csak az egyes korpuszokra jellemző jegyeket (pl.~főnévi csoportok jelölése, Wikipédia linkek) kidobtuk, hogy növeljük a korpuszok összehasonlíthatóságát. Így a következő jegykészlettel dolgoztunk: mondatkezdő és -vég pozíciók, szóalakon alapuló jegyek, morfológiai információ és listajegyek. 

A kiértékeléshez a sztenderd CoNLL módszert alkalmaztuk, vagyis az annotációt csak akkor vettük helyesnek, ha a kezdő- és végpozíció is stimmelt, és a rendszer által kibocsátott címke megegyezett a gold standard címkével. Ezen alapulva a szokásos pontosságot, fedést és F-mértéket számoltuk. 

\subsection{Az adatok}

A korpuszok a fent leírt szűrő eljárások után maradt mondatokat tartalmazzák, így azokat is, amelyekben nincs egy név sem. Ezeket azért tartottuk meg, hogy amennyire lehetséges, megőrizzük a nevek eredeti, Wikipédia-beli eloszlását. Viszont amikor megvizsgáltuk az egyes korpuszok telítettségét a nevek szempontjából, arra jutottunk, hogy a gold standard adathalmazokkal való összevetésükkor inkább sűrítjük a szövegeket, vagyis kivesszük azokat a mondatokat, amelyekben nincs név. A \ref{tab:size_en}.~és \ref{tab:size_hu}.~táblázatok mutatják az egyes korpuszokra vonatkozó számszerű adatokat, melyekből jól látható, hogy a Wikipédiából generált korpuszok telítettsége meglehetősen alacsony, a nevet nem tartalmazó mondatok kiszűrése után viszont hasonlóak lettek a számok. Mivel a Wikipédia az entitások kincsesbányájaként van számon tartva, ezek az adatok kissé meglepőek lehetnek. A szövegeknek ez a hígsága valószínűleg annak köszönhető, hogy a módszerünk szigorú, vagyis inkább minden olyan mondatot eltávolítottunk, amelyben nem lehetett beazonosítani a nevet, minthogy rosszul annotált nevek maradjanak benne. 

\begin{table}[ht]
\begin{center}
\begin{tabular}{lccc}
\toprule  
& \textbf{enwiki} & \textbf{enwiki filter} & \textbf{CoNLL} \\ 
\midrule
token & 60,520,819 & 21,718,854 & 301,418 \\
NE & 3,169,863 & 3,169,863 & 35,089 \\
telítettség (\%) & 5.23 & 14.59 & 11.64 \\
\hline
\end{tabular}
\end{center}
\caption{Az angol korpuszok mérete és telítettsége.}
\label{tab:size_en}
\end{table}
 
\begin{table}[ht]
\begin{center}
\begin{tabular}{lccc}
\toprule
 & \textbf{huwiki} & \textbf{huwiki filter} & \textbf{Szeged NER} \\
\midrule
token & 19,108,027 & 3,512,249  & 225,963 \\
NE & 456,281 & 456,281  & 25,896 \\
telítettség (\%) & 2.38 & 12.99 & 11.46 \\
\bottomrule
\end{tabular}
\end{center}
\caption{A magyar korpuszok mérete és telítettsége.}
\label{tab:size_hu}
\end{table}

\subsection{Kísérletek és eredmények}

A magyar és az angol korpuszok is hasonlóan lettek kiértékelve: először saját magukon, aztán egy választott gold standard adathalmazon. Mivel az angol korpusz még a nevet nem tartalmazó mondatok eltávolítása után is nagyon nagy, kísérleteinket egy kb.~3,5 millió tokenes részén végeztük (a szűrt magyar korpusz is ekkora), 90-10\%-os arányban vágva tanító és kiértékelő korpuszra.  

Az angol korpusz kiértékeléséhez a 2003-as CoNLL korpuszt, a magyarhoz pedig a Szeged NER korpuszt választottuk. Többek által (pl. \cite{Nothman:08} és \cite{ciaramita2005}) bizonyított tény, hogy a korpuszok közötti kiértékelés sokkal rosszabb eredményt ad, mint a saját kiértékelő halmazon való mérés. Különböző típusú szövegek esetén a különbség 20-30\% is lehet. A helyzet a mi esetünkben is nagyon hasonló (lásd a \ref{tab:enresults}.~és \ref{tab:huresults}.~táblázatokat az eredményekért): a Wikipédián tanított rendszerek teljesítménye közel sem olyan jó a gold standard korpuszok kiértékelő halmazán mérve, mint a saját kiértékelő halmazukon. 

\begin{table}[ht]
\begin{center}
\begin{tabular}{lcccc}
\toprule 
\textbf{tanítás} & \textbf{teszt} & \textbf{pontosság} & \textbf{fedés} & \textbf{F-mérték} \\ 
\midrule
CoNLL & CoNLL & 85.13 & 85.13 & 85.13 \\
enwiki & enwiki & 72.46 & 73.33 &  72.89 \\
enwiki & CoNLL & 56.55 & 49.77 & 52.94 \\
CoNLL\_wikilisták & CoNLL & 86.33 & 86.35 & 86.34 \\
CoNLL\_wikitag & CoNLL & 85.88 & 85.94 & 85.91 \\
\bottomrule
\end{tabular}
\end{center}
\caption{Eredmények az angol Wikipédia korpuszon.}
\label{tab:enresults}
\end{table}

\begin{table}[ht]
\begin{center}
\begin{tabular}{lcccc}
\toprule 
\bf tanítás & \bf teszt & \bf pontosság & \bf fedés & \bf F-mérték \\ 
\midrule
Szeged & Szeged & 94.50 & 94.35 & 94.43 \\
huwiki & huwiki & 90.64 & 88.91 &  89.76 \\
huwiki & Szeged & 63.08 & 70.46 & 66.57 \\
Szeged\_wikilisták & Szeged & 95.48 & 95.48 & 95.48 \\
Szeged\_wikitag & Szeged & 95.38 & 94.92 & 95.15 \\
\bottomrule
\end{tabular}
\end{center}
\caption{Eredmények a magyar Wikipédia korpuszon.}
\label{tab:huresults}
\end{table}

A Wikipédia korpuszokat más módon is használhatjuk a tulajdonnév-felismerés teljesítményének növelése érdekében. Egy kézenfekvő megoldás nagyméretű névlisták kinyerése a Wikipédiából, és azok hozzáadása gazetteer listaként a tanításhoz. Ez a módszer mindkét nyelv esetében növelte az F-mértéket. Egy másik kísérletünkben a rendszert a Wikipédia korpuszon tanítottuk, majd az általa kibocsátott címkéket jegyként hozzáadtuk a gold standard korpuszon való tanításhoz és teszteléshez. Ezzel a módszerrel is sikerült javítani a rendszer teljesítményét. 

Ha összehasonlítjuk a magyar és az angol eredményeket, azt látjuk, hogy a magyar korpuszokon szignifikánsan jobb eredményeket értünk el. Ennek több oka is lehet. Az egyik, hogy a magyar nyelv esetében a \texttt{Misc} kategóriába sokkal kevesebb dolog tartozik, vagyis kevésbé heterogén, így kevesebb hibát lehet elkövetni az automatikus annotálás során. És ahogy a magyar korpuszon végzett kézi hibaelemzés eredménye is mutatja, tényleg sikerült elkerülni az esetek nagy részében a félrecímkézéseket. A másik ok az lehet, hogy a magyar esetében használt silver és gold standard adathalmazok egyaránt sokkal tisztábbak, a NE-annotálás pontosabb, mint az angol erőforrások esetében. Mivel az automatikusan épített magyar korpuszunk közelíti a gold standard minőséget, mondhatjuk, hogy olyan erőforrást sikerült létrehoznunk, amely használható tulajdonnév-felismerő rendszerek tanító és kiértékelő korpuszaként, akár önállóan, akár kiegészítve a gold standard korpuszokat. 

\section{Összegzés}
\label{conc}

Cikkünkben egy olyan új módszert mutattunk be, amellyel magyar és angol nyelvű, automatikusan tulajdonnév-annotált korpuszokat hoztunk létre a Wikipédiából. Az eddig alkalmazottakkal ellentétben a mi metódusunk egy leképezést valósít meg a DBpedia ontológiai osztályairól a hagyományos címkekészletekre. Az így generált címkéket aztán a rendszer hozzárendeli a Wikipédiában szereplő entitásokhoz. 

Módszerünk nyilvánvaló előnyei, hogy nagyban csökkenti az annotálás költségeit, valamint hogy sokkal nagyobb adathalmazokat állíthatunk elő általa, mint kézi annotációval. Egy másik előnye, hogy bármely Wikipédiával rendelkező nyelvre alkalmazható, így kevés erőforrással rendelkező nyelvekre is előállíthatunk silver standard korpuszokat. A létrehozott korpuszok a továbbiakban számos módon alkalmazhatók a tulajdonnév-felismerő rendszerek hatékonyságának növelésére. Amennyiben kellően tiszta a korpusz, vagy az adott nyelvre nem létezik gold standard tisztaságú adathalmaz, felügyelt gépi tanulási rendszerekhez használható tanításhoz és kiértékeléshez. Továbbá erőforrásokkal bővebben ellátott nyelvek esetében is hasznosítható a klasszikus sajtó stílustól eltérő szövegek tulajdonnév-annotálásához. 

További, újdonságnak számító eredményünk, hogy az általunk előállított korpuszok szabadon elérhetőek és felhasználhatóak. Tudomásunk szerint ez az első magyar nyelvű automatikusan előállított tulajdonnév-annotált korpusz. Az angol erőforrások tekintetében is hasonló a helyzet: jelenleg a Semantically Annotated Snapshot of English Wikipedia mellett az itt publikált korpusz az egyetlen szabadon felhasználható tulajdonnév-annotált korpusz. 

Jelen cikkünkben a DBpedia ontológiai kategóriáit a sztenderd tulajdonnév-címkékre képeztük le, de a módszerben benne rejlik a lehetőség finomabbra hangolt tulajdonnév-hierarchiák támogatására is. Az internetes közösség által létrehozott tartalmak, mint a Wikipédia és a DBpedia, folyamatosan növekszenek, ezáltal egyre több információ felhasználását teszik lehetővé. A módszer frissítésével egyre nagyobb és finomabban annotált korpuszokat tudunk létrehozni a jövőben.  

\section*{Köszönetnyilvánítás}
A fejlesztés az OTKA 82333 számú projektjén belül valósult meg. A fejlesztést támogatta továbbá a CESAR projekt (No. 271022). A szerzők ezúton fejezik ki köszönetüket Zséder Attilának a Wikipédia szövegek feldolgozásában végzett munkájáért, és Kornai Andrásnak támogatásáért. %vagy mi

\bibliographystyle{plain}
\bibliography{cikk}

\end{document}
