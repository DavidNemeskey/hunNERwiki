\documentclass{llncs}

\usepackage[a4paper,includeheadfoot,top=1.65in,bottom=1.65in,left=1.73in,hcentering]{geometry}
\usepackage[pdftex]{graphicx}

\usepackage[utf8]{inputenc}

\usepackage[magyar]{babel}
\selectlanguage{magyar} 
\usepackage{t1enc}
%\input huhyphn.tex
\hyphenation{DBpedia Sharealike}

\begin{document}

\pagestyle{myheadings}
\def\leftmark{{\rm IX. Magyar Sz\'am\'\i t\'og\'epes Nyelv\'eszeti Konferencia}}
\def\rightmark{{\rm Szeged, 2013. január 7-8.}}

\setcounter{page}{3}

\title{\ \break Automatikusan tulajdonnév-annotált korpuszok előállítása a Wikipédiából}
\author{Nemeskey Dávid Márk\inst{1}, Simon Eszter\inst{2}}
\institute{
\inst{}%
MTA SZTAKI \break
1111 Budapest, Lágymányosi utca 11., e-mail:nemeskey@sztaki.mta.hu \break
\and
\inst{}%
MTA Nyelvtudományi Intézet \break
1068 Budapest, Benczúr u. 33., e-mail: simon.eszter@nytud.mta.hu}

\maketitle

%\section{Introduction}

%Az automatikus tulajdonnév-felismerés (Named Entity Recognition, NER) a természetes nyelv feldolgozását célzó alkalmazások közül az egyik legnépszerűbb, mivel hatékonyan automatizálható, és eredménye hasznos bemenete különböző magasabb szintű információkinyerő és -feldolgozó rendszereknek. A feladat során strukturálatlan szövegben kell azonosítani és az előre definiált osztályok valamelyikébe besorolni a neveket. Az egyik leggyakrabban alkalmazott nemzetközi sztenderd a CoNLL-2003 verseny kiírását követi, amely szerint a négy névkategória a következő: személy-, intézmény-, földrajzi név és az ezek egyikébe sem tartozó egyéb kategória. 

%Named Entity Recognition (NER), the task of identifying Named Entities (NEs) in unstructured texts and classifying them into pre-selected classes, is one of the most important subtasks in many NLP tasks, such as information retrieval, information extraction or machine translation. MUC and CoNLL datasets and annotation schemes have been the major standards applied in the field of NER. 

% So that DBpedia-típus and Sharealike do not generate overfull hbox.
\pretolerance=1000

Az automatikus tulajdonnév-felismerés (Named Entity Recognition, NER) során alkalmazott
gold standard korpuszok általában műfajspecifikusak (főleg rövidhírek), és korlátozott
méretűek. Egy kellően robusztus alkalmazás építéséhez viszont nagy méretű és változatos
nyelvi anyagot tartalmazó adathalmazra van szükség. A tanítókorpuszok előállítása
hagyományosan kézi annotálás útján tör\-té\-nik, ami meglehetősen sok időt, szakértelmet és
pénzt kíván, vagyis kardinális kérdés az erőforrások minimalizálása. Nagyobb
tanítóhalmazhoz juthatunk, ha már meglevő korpuszokat egyesítünk; ebben az esetben
viszont azzal kell szembesülnünk, hogy ezek különböző annotációs sémát követnek. 

Ezen problémák kiküszöbölésére egy lehetséges módszer, ha automatikusan állítunk elő  
adathalmazokat, vagy pedig olyan közösségi tartalmakat használunk fel, mint pl. a
Wikipédia, a Wiktionary vagy a DBpedia. Cikkünkben olyan módszert mutatunk be, mely ezek
kombinációja, és amely a Wikipédiából automatikusan állít elő tulajdonnév-annotált
korpuszokat.

%The standard datasets are highly domain-specific (mostly newswire) and are
%restricted in size. Researchers attempting to merge these datasets to get a bigger training corpus are faced with the
%problem of combining different tagsets and annotation schemes. Manually
%annotating large amounts of text with linguistic information is a
%time-consuming, highly skilled and delicate job, but large, accurately
%annotated corpora are essential for building robust supervised machine
%learning NER systems. Therefore, reducing the annotation cost is a key
%challenge.

%One approach is to generate the resources automatically, another one is to use
%collaborative annotation and/or collaboratively constructed resources, such as
%Wikipédia, Wiktionary, Linked Open Data, or DBpedia. In this paper we combine
%these approaches by automatically generating freely available NE tagged
%corpora from Wikipédia.

%\section{Wikipédia and NER}

A Wikipédia a legismertebb, önkéntesek által szerkesztett nyílt internetes
enciklopédia. Mivel ez az egyik
legnagyobb elérhető forrása az entitásoknak, a NER teljesítményének növelésére több
módon is kiválóan használható. Nyilvánvaló felhasználási
módja különböző névlisták kinyerése (pl. \cite{Toral_2006.a}); de a Wikipédiában található
tudás a tanuló algoritmus számára használható jegyek formájában is beépíthető felügyelt
tanulási rendszerekbe (pl. \cite{KaTo07}). 

Számos példát találunk arra is a nemzetközi irodalomban, amikor a Wikipédiából építenek
korpuszt, amelyben az entitásokra vonatkozó információt valamilyen formában megőrzik és
feldolgozzák. Ezt az irányt követtük mi is, de az eddig alkalmazott módszerek
helyett új megközelítést alkalmaztunk. Cikkünkben bemutatjuk a feldolgozás
folyamatát és eredményét: egy magyar és egy angol nyelvű automatikusan
tulajdonnév-annotált korpuszt.

%Wikipédia (WP, see {\tt http://wikipedia.org}), a free
%multilingual Internet encyclopedia, written collaboratively by volunteers, is
%a goldmine of information.
%WP has been applied to several NLP tasks such as word sense
%disambiguation, ontology and thesaurus building, and question answering (see
%Medelyan et al.~\cite{Medelyan:09} for a survey). It is recognized as one
%of the largest available collections of entities, and also as a resource that
%can improve the accuracy of NER. The most obvious utilization of WP for NER is
%extracting gazetteers containing person names, locations or organizations
%(e.g.~Toral and Mu\~noz \cite{Toral:06}). Creating dictionaries of
%entities is also a common step of NE disambiguation
%\cite{Bunescu:06,Cucerzan:07}. Both supervised and unsupervised NER systems
%use such lists, see e.g.~Nadeau et al.~\cite{Nadeau:06} The knowledge
%embodied in WP may also be incorporated in NER learning as features,
%e.g.~Kazama and Torisawa \cite{Kazama:07} showed that automatic
%extraction of category labels from WP improves the accuracy of a supervised NE
%tagger.

%Another approach to improve NER with WP is the automatic creation of training
%data. Nothman et al.~\cite{Nothman:08} used a similar method to create
%a NE annotated text in English. They transformed the WP links into NE
%annotations by classifying the target articles into standard entity
%classes. Their approach to classification is based primarily on category head
%nouns and the opening sentences of articles where definitions are often given.

%Our approach to recognize and classify NEs in corpora generated from WP was to
%map the DBpedia ontology classes to standard NE tags and assign these to WP
%entities. the one presented here is the first automatically NE annotated corpus for Hungarian.

%\section{Creating the Corpus}
%\subsection{Creating the English Corpus}

A korpuszokat, hasonlóan Nothman et al.~\cite{Nothman:08} munkájához, a következő
lépésekkel állítottuk elő:
 
\begin{enumerate}
\item a Wikipédia-cikkeket entitásosztályokba soroltuk;
\item a cikkeket mondatokra bontottuk;
\item felcímkéztük a tulajdonneveket a szövegben;
\item kiszűrtük a rossz minőségű mondatokat.
\end{enumerate}

Bár Nothman az első feladatot gépi tanulással oldotta meg, mi a nagyobb
pontosság érdekében a DBpedia~\cite{Bizer:09} tudásbázis alapján osztályoztuk az
entitásokat. A tulajdonneveket Wikipédia kereszthivatkozások segítségével azonosítottuk.
Minden olyan mondatot, ahol ismeretlen név fordult elő, eldobtunk.

A fenti lépések mindegyike automatikus; emberi beavatkozást egyedül a DBpedia-típusok
sztenderd CoNLL névkategóriákra történő leképezése jelent. A módszer jórészt
nyelvfüggetlen; ennek alátámasztására egy magyar és egy angol nyelvű korpuszt is
előállítottunk. A cikkben részletesen is kitérünk a két Wikipédia sajátosságaira, a
nyelvi és NER konvenciók különbségéből fakadó eltérésekre.

%\section{Evaluation}

Az automatikus annotálás nyilvánvaló előnyei mellett meg kell vizsgálnunk azt is, hogy az
eredményül kapott  ún. ,,silver standard'' korpuszok hogyan hasznosíthatók a NER
teljesítményének növelésére. A már említett lehetőségek (névlisták kinyerése, jegyként
való beépítés) mellett ezek a korpuszok önmagukban vagy más adathalmazokkal együttesen
tanítókorpuszként szolgálhatnak a kevesebb erőforrással rendelkező nyelvekre, illetve a
rövidhírektől eltérő műfajokra is. A magyar és az angol korpuszon végzett kísérletek
egyaránt azt igazolják, hogy a Wikipédiából automatikusan előállított adathalmazok
javítják a NER teljesítményét. Cikkünkben részletes hibaelemzést adunk, és megvizsgáljuk
a magyar Wikipédia és a Szeged NE korpusz\cite{Szarvas:06} annotációsémája közötti
eltéréseket.

%\section{Data description}

A korpusz a Wikipédiához hasonlóan a Creative Commons Attribution-Sharealike
3.0 Unported (CC-BY-SA) licensz alatt érhető el. Szabadon letölthető a SZTAKI HLT
csoportjának\footnote{\texttt{http://hlt.sztaki.hu}} oldaláról és a META-SHARE
tárhelyről\footnote{\texttt{http://nlp.ipipan.waw.pl/metashare}}.

%\section{Conclusion}

%
% ---- Bibliography ----
%
\bibliographystyle{huplain}
\bibliography{abstract}

\end{document}
