% $Header: /home/vedranm/bitbucket/beamer/solutions/generic-talks/generic-ornate-15min-45min.en.tex,v 90e850259b8b 2007/01/28 20:48:30 tantau $

\documentclass[utf8x]{beamer}

\mode<presentation>
{
%  \usetheme[height=7mm]{Rochester}
  \usetheme{Rochester}
  \useinnertheme{rounded}
%  \useoutertheme{infolines}
  % or ...

  \setbeamercovered{transparent}
}
\usefonttheme[onlymath]{serif}

\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}

\usepackage{times}
\usepackage[T1]{fontenc}
% Or whatever. Note that the encoding and the font should match. If T1
% does not look nice, try deleting the line with the fontenc.

%% to draw trees without jpg figures
%\usepackage{synttree}
% For code blocks
\usepackage{algorithm}  % Conflict w/ synttree
\usepackage{algorithmic}
% for sane tabular handling
\usepackage{array}
% For strikethrough (normalem keeps it as emph)
\usepackage[normalem]{ulem}

\usepackage{mathrsfs}
\usepackage{bm}  % For bold math

\newcommand{\vitem}{\vfill \item}
\newcommand{\nyil}{$\rightarrow$\ }

\newtheorem{nix}{}[section]

\title % (optional, use only with long paper titles)
{Automatically generated NE tagged corpora for English and Hungarian}

%\subtitle
%{Presentation Subtitle} % (optional)

\author % (optional, use only with lots of authors)
{Eszter Simon\inst{1}, Dávid Márk Nemeskey\inst{2}}

\institute{\inst{1} Research Institute for Linguistics, Hungarian Academy of Sciences \\
\inst{2} Computer and Automation Research Institute, Hungarian Academy of Sciences} % (optional, but mostly needed)
% - Use the \inst command only if there are several affiliations.
% - Keep it simple, no one is interested in your street address.

\date % (optional)
{2012.07.12.}

% \subject{Talks}
% This is only inserted into the PDF information catalog. Can be left
% out. 



% If you have a file called "university-logo-filename.xxx", where xxx
% is a graphic format that can be processed by latex or pdflatex,
% resp., then you can add a logo as follows:

% \pgfdeclareimage[height=0.5cm]{university-logo}{university-logo-filename}
% \logo{\pgfuseimage{university-logo}}

\AtBeginSection[]
{
   \begin{frame}
       \frametitle{Outline}
       \tableofcontents[currentsection]
   \end{frame}
}


% If you wish to uncover everything in a step-wise fashion, uncomment
% the following command: 
%\beamerdefaultoverlayspecification{<+->}


\begin{document}

% TODO: kell outline?
\begin{frame}{}
  \titlepage
\end{frame}

\section{Introduction}

\begin{frame}{Datasets}

The standard datasets are

\begin{itemize}
\item highly domain-specific
\item restricted in size
\end{itemize}

\bigskip

To get a bigger training corpus:

\begin{itemize}
\item merging datasets \nyil problems of combining different tagsets
\item manual annotation \nyil not cost-effective
\end{itemize}

\end{frame}

\begin{frame}{Reducing the annotation cost}

Reducing the annotation cost:

\begin{itemize}
\item to generate the resource automatically 
\item to use collaboratively constructed resources (e.g.~Wikipedia, DBpedia)
\end{itemize}

\bigskip

\begin{nix}
combining these approaches: \\ automatically generating NE tagged corpora from Wikipedia
\end{nix}

\end{frame}

%\section{Wikipedia and NER}

\begin{frame}{Wikipedia and NER}

\begin{nix}
Wikipedia is one of the largest available collections of entities
\end{nix}

\smallskip

Improving the accuracy of NER with WP:

\begin{itemize}
\item extracting gazetteers containing person names, locations and organizations 
\item extracting the knowledge embodied in WP and incorporating it in NER learning as features
\item automatic creation of training data from WP
\begin{itemize}
\item by using the category structure of WP
\item by using the category head nouns and the opening sentences of articles
\end{itemize} 
\end{itemize}

\end{frame}

\begin{frame}{Our approach}

\begin{nix}
mapping the DBpedia ontology classes to standard NE tags, and assign them to WP entities
\end{nix}

\bigskip

our method is largely language-independent \nyil sufficiently large corpora for less resourced languages can be built 

\bigskip

\begin{nix}
this is the first automatically annotated corpus for Hungarian 
\end{nix}

\end{frame}

\section{Creating the English Corpus}

\subsection*{Motivation}
\begin{frame}{Blabla}
\end{frame}
\subsection{Articles to Entities}
\begin{frame}{Problem Statement}
  In many real world applications the problem is to predict outputs with a nontrivial structure given some inputs.
  \vfill
  Example: \textit{\small It was love at first sight.}
  \vfill
\end{frame}

\section{Creating the Hungarian Corpus}

\begin{frame}{The Hungarian Corpus}
  The algorithm is, in theory, language-agnostic. We tested this property by
  applying it to a medium-sized language, Hungarian. \\
  Difference from bigger, well-resourced languages:
  \begin{itemize}
  \vitem E % TODO: ide mit?
  \end{itemize}
\end{frame}

\begin{frame}{Differences from English}
  \begin{itemize}
  \vitem Language processing tools
    \begin{itemize}
    \vitem Inflectional morphology: different set of tools were needed 
    \vitem We developed a flexible framework that enables the plugging of any NLP tool
    % TODO: what kind of linguistic tools are needed: table?
    \end{itemize}
  \vitem Wikipedia size and coverage
    \begin{itemize}
    \vitem Hungarian is medium-size language: ~200k articles vs. ~4M English pages
    \vitem Cross-references may point to English pages
    \vitem Templates are in Hungarian: per-language template configuration
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}{Differences from English -- cont.}
  \begin{itemize}
  \vitem DBpedia coverage
    \begin{itemize}
    \vitem Internationalized chapters for big languages only
    \vitem "Hungarian" DBpedia list contains English articles % Nem egyértelmű
      \begin{itemize}
      \vitem Hungarian equivalents must be added to the list % Added: lásd előző oldal 2/2
      \vitem Hungarian entities without an English page are missing:
             the NER language model might not be accurate
      \vitem Future work: extend the list with the missing Hungarian entities
      \end{itemize}
    \end{itemize}
  \vitem NE conventions
    \begin{itemize}
    \vitem Szeged NER guideline: similar to CoNLL
    \vitem Common nouns in Hungarian: names of languages, religions, months, etc.
    % TODO: compounding
    \end{itemize}
  \end{itemize}
\end{frame}

\section{Data description}

\begin{frame}{Data format}

\begin{tabular}{llllll}
\textbf{token} & \textbf{text/link} & \textbf{WP link} & \textbf{POS} & \textbf{lemma} & \textbf{NE} \\
This & text & 0 &    DT &   This & O \\
is &   text & 0 &    VBZ &  be &   O \\
a &    text & 0 &    DT &   a  &    O\\
list & text & 0 &    NN &   list  & O\\
of &   text & 0 &    IN &   of &     O\\
films  & B-link & films &  NNS &  film & O\\
by &   text & 0 &    IN &   by &     O\\
year & text & 0 &    NN &   year & O\\
produced & text & 0 &    VBN &  produce & O\\
in &   text & 0 &    IN &   in &     O\\
the &  text & 0 &    DT &   the &   O\\
country &text & 0 &    NN &   country &O\\
of &   text & 0 &    IN &   of &     O\\
South &  B-link & South Korea &  NNP &  South  &B-LOC\\
Korea &  I-link & South Korea &  NNP &  Korea   & I-LOC\\
\end{tabular}

\end{frame}

\begin{frame}{Data description}

\begin{itemize}
\item available under CC-BY-SA 3.0 Unported License
\item freely downloadable from {\tt http://hlt.sztaki.hu/resources/} 
\item also distributed through META-SHARE (from 1 August)
\end{itemize}

\end{frame}

\section{Evaluation}

\begin{frame}{Corpus size and NE density}

English: 

\smallskip

\begin{center}
\begin{tabular}{llll}
\hline  & \bf enwiki & \bf enwiki filtered & \bf CoNLL \\ \hline
token & 60,520,819 & 21,718,854 & 302,811 \\
NE & 3,169,863 & 3,169,863 & 50,758 \\
NE density & 5.23\% & 14.59\% & 16.76\% \\ \hline
\end{tabular}
\end{center}

\smallskip

Hungarian:

\smallskip

\begin{center}
\begin{tabular}{llll}
\hline  & \bf huwiki & \bf huwiki filtered  & \bf Szeged NER \\ \hline
token & 19,108,027 & 3,512,249  & 225,963 \\
NE & 456,281 & 456,281  & 25,896 \\
NE density & 2.38\% & 12.99\%  & 11.46\% \\ \hline 
\end{tabular}
\end{center}

\end{frame}

\begin{frame}{English results}

\begin{center}
\begin{tabular}{lllll}
\hline \bf Train & \bf Test & \bf P (\%) & \bf R (\%) & \bf F (\%) \\ \hline
CoNLL & CoNLL & 85.13 & 85.13 & 85.13 \\
enwiki & enwiki & 72.46 & 73.33 &  72.89 \\
enwiki & CoNLL & 56.55 & 49.77 & 52.94 \\
CoNLL with wikilists & CoNLL & 86.33 & 86.35 & 86.34 \\
CoNLL with wikitags & CoNLL & 85.88 & 85.94 & 85.91 \\
\hline
\end{tabular}
\end{center}

\end{frame}

\begin{frame}{Hungarian results}

\begin{center}
\begin{tabular}{lllll}
\hline \bf Train & \bf Test & \bf P (\%) & \bf R (\%) & \bf F (\%) \\ \hline
Szeged  & Szeged  & 94.50 & 94.35 & 94.43 \\
huwiki & huwiki & 90.64 & 88.91 &  \textbf{89.76} \\
huwiki & Szeged  & 63.08 & 70.46 & 66.57 \\
Szeged  with wikilists & Szeged  & 95.48 & 95.48 & 95.48 \\
Szeged  with wikitags & Szeged  & 95.38 & 94.92 & 95.15 \\
\hline
\end{tabular}
\end{center}


\end{frame}

\section{Conclusions}
\begin{frame}{Results -- cont.}
  Single hold-out vs. cross-validation:
  \begin{itemize}
  \vitem Single hold-out is biased
  \vitem cross-validation gives more stable results
  \end{itemize}
  \vfill
\end{frame}

\end{document}


