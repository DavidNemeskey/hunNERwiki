%
% File acl2012.tex
%
% Contact: Maggie Li (cswjli@comp.polyu.edu.hk), Michael White (mwhite@ling.osu.edu)
%%
%% Based on the style files for ACL2008 by Joakim Nivre and Noah Smith
%% and that of ACL2010 by Jing-Shin Chang and Philipp Koehn


\documentclass[11pt]{article}
\usepackage{acl2012}
\usepackage{times}
\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{url}
\usepackage[utf8]{inputenc}
\DeclareMathOperator*{\argmax}{arg\,max}
\setlength\titlebox{6.5cm}    % Expanding the titlebox

\title{XXX}

%\author{Dávid Márk Nemeskey \\
%  Research Institute for Computer Science and Automation \\
%  Hungarian Academy of Sciences \\
%  H-1111 Lágymányosi út 11, Budapest \\
%  {\tt nemeskey.david@sztaki.hu} \\\And
%  Eszter Simon \\
%  Research Institute for Linguistics \\
%  Hungarian Academy of Sciences \\
%  H-1068 Benczúr utca 33, Budapest \\
%  {\tt eszter@nytud.hu} \\}

\date{}

\begin{document}
\maketitle
\begin{abstract}
  
\end{abstract}

\section{Introduction}

Named Entity Recognition (NER), the task of identifying Named Entities (NEs) in unstructured texts and classifying them into pre-selected classes, is one of the most important subtasks in many NLP tasks, such as Information Retrieval, Information Extraction or Machine Translation. The NER task was introduced with the 6th Message Understanding Conference (MUC) in 1995. In MUC shared tasks the NER consists of three subtasks: entity names, temporal expressions and number expressions. However there is a general agreement in the NER community about the inclusion of temporal expressions and some numerical expressions such as amounts of money and other types of units, the most studied types are names of persons, locations and organizations. The fourth type, called "miscellaneous", is used in the CoNLL NER tasks in 2002 and 2003, and includes proper names falling outside the three classic types. Since then, MUC and CoNLL datasets and annotation schemes have been the major standards applied in the field of NER.    

The standard datasets are highly domain-specific (mostly newspaper articles about company activities and defense related activities), and are restricted in size, as well. Thus they are not large enough to train and test robust NE-taggers on them. Moreover, merging these datasets to get a bigger training corpus faces NLP researchers with the problem of combining different tagsets and annotation schemes. However, to build a robust supervised machine learning system for NER, large enough, accurately annotated corpora are essential. Annotating large amount of texts with linguistic information is a time-consuming, highly skilled and delicate work. Mainly due to this fact, one of the main challenges in NLP is reducing the annotation cost. 

One approach to reduce the manual intervention required in language resource production, and thus ultimately production costs is automatically generating resources. An other approach to achieve this aim is using collaborative annotation and/or collaboratively constructed resources, such as Wikipedia, Wiktionary or Linked Open Data. Researchers apply the Web-as-corpus approach, often dealing with such datasets as the Google 5G 1T collection or DBPedia. Thanks for the huge amount of Wikipedia articles, the possibility of building large enough corpora is given for less resourced languages, as well.  

%One of the main trends in NLP is the need for reducing the annotation cost. After examining the calls for papers of nowadays conferences and workshops there seems to be three major directions to achieve this aim. 

%The first approach is the application of unsupervised and semi-supervised learning techniques. Researchers following this approach try to not only reduce, but avoid the annotation cost with minimizing the need for annotated data. These methods can be applied to any language or genre for which adequate raw text resources are available. 

In this paper we present a kind of combination of the approaches mentioned above. We built NE-tagged corpora for English and Hungarian -- fully automatically generated from Wikipedia. Our goal was to create gold standard corpora which can serve as train, devel and test datasets for automatic NE-taggers. 

The paper is structured as follows. XXX


\section{Related Work}
% Wikify!
% stuff from Mining Meaning from Wikipedia
%NER and Wikipedia

Wikipedia is a goldmine of information; it is applied for several NLP tasks, e.g.~word sense disambiguation, ontology and thesaurus building, multilingual Information Retrieval, and Question Answering, as Medelyan et al.~\shortcite{Medelyan:09} point out in their fully detailed survey about mining meaning from Wikipedia. 

Wikipedia is recognized as one of the largest available collection of entities, and also as an external knowledge to improve the accuracy of NER. The most obvious utilization of Wikipedia for NER is extracting gazetteers containing person names, locations or organizations \cite{Toral:06}. Creating dictionaries of entities is also a common step of named entity disambiguation \cite{Bunescu:06,Cucerzan:07}. Not only supervised systems use lists generated from Wikipedia: Nadeau et al. \shortcite{Nadeau:06} use similar lists in an unsupervised NER system. 

Wikipedia's knowledge may be incorporated as features in NER learning, e.g. Kazama and Torisawa \shortcite{Kazama:07} showed that automatic extraction of category labels from Wikipedia improves the accuracy of a supervised NE-tagger. 

A third approach to improve NER with Wikipedia is the automatic creation of training data. Richman and Schone \shortcite{Richman:08} built corpora for less commonly taught languages annotated with NE-tags. They used the inherent category structure of Wikipedia to determine the NE-type of a proposed entity. Nothman et al.~\shortcite{Nothman:08} used a similar method to create a NE-annotated text in English. They transformed the Wikipedia links into NE-annotations by classifying the target articles into standard entity classes. Their approach to classification is based primarily on category head nouns and definitional opening sentences of articles. 

not open access XXX

más nyelvekre is csinálták XXX

domain-specificity: not really

Szeged NER korpusz kicsi, ahhoz képest ez nagy

DBPediát előrébb 

%Exploiting Wikipedia as external knowledge for NER:
%%-creating entity lists  
%%-disambiguating named entities
%%-automatic extraction of category labels from Wikipedia to improve the accuracy of a CRF-based NE-tagger \cite{Kazama:07}
%-entity ranking
%-typing named entities

%Automatic creation of training data from Wikipedia for NER:
%-classification of articles into CoNLL entity classes \cite{Nothman:08}

\section{Creation of the Corpus}  % Dzsííízösz

% Introduction: Wikipedia + DBpedia
The corpora are available in the tab separated format used by ConLL (XXX, CITE). In this format, one line contains one word, its linguistic features and the named entity tags. Sentence boundaries are marked by empty lines. The linguistic features include the lemmatized form of the word, part-of-speech tag and chunk tag. Two named entity tags are included with each word: one is the most specific DBpedia category it belongs to, if any; the other is the ConLL named entity tag. While the named entity tags can be considered "gold", the linguistic features are provided on a "best-effort" basis (XXX: check the LREC paper to find a better wording for this).
XXX: past or present tense?

We decided to use Wikipedia because

The categories of Wikipedia are too numerous and ; not a tree;

Wikipedia proves to be a rich source of information about its entities; aside from the article text, a huge amount of data is encompassed in infoboxes, templates and the category structure. Since our goal is to create a NER training corpus, our interest is limited to the article text. Templates are removed from the articles; however, the names of the templates have been retained for XXX, but all data (including infobox) 

Beside regular articles, Wikipedia also contains redirect and disambiguation pages, which require special treatment. Redirect pages are empty and are safe to ignore altogether. Disambiguation pages contain text, usually in the form of an enumeration of page links with a short description. Full sentences are scarce and the structure of these pages makes it hard to extract valid training sentences from them. Therefore, disambiguation pages have been dropped from the corpus as well.

The corpus is based on the Wikipedia snapshot as of XXX. The xml files were parsed with the XXX (Attila) parser. The raw text was tokenized with a modified version of the XXX sentence tokenizer in NLTK (CITE). The words were lemmatized with XXX and POS tagged with HunPos (CITE). Chunking was performed with HunChunk (CITE). Experiments have shown that HunPos obtains STAT f-score on the Brown corpus; HunChunk performs at around STAT, CITE?.

\subsection{Extraction of the Training Sentences}

A NER training corpus consists of sentences that accurately tag named entities occurring in them. In order to automatically prepare such sentences, two tasks need to be performed: identification of entities in the sentence and tagging them with the correct tag. Sentences, for which accurate tagging could not be accomplished, must be removed from the corpus. In this section, we describe how these steps were implemented, as well as the post-filtering we employed to dispose of correctly tagged but unusable training sentences.

\subsubsection{Entity identification}
% TODO: identification and tagging happens in parallel, else the recall oriented approach cannot be explained.

Our approach to entity identification relies on Wikipedia cross-references found in the article text. We assume that individual Wikipedia articles describe named entities. A link to an article can then be perceived as a mapping that identifies its anchor text with a particular entity. There are exceptions to this rule, however. Disambiguation pages are used when the page title is ambiguous, and can refer to several entities. If a link points to a disambiguation page, we acknowledge the anchor text as an entity, but mark it unknown. A similar measure is taken if the link target XXX does not exist. Links to redirect pages are resolved to point instead to the redirect target, after which they are handled as regular cross-references.

Not all entities are marked with links, however. Authors may neglect to add XXX references to their text. Furthermore, in a Wikipedia article XXX, typically only the first occurrence of a particular entity is linked to the corresponding page. Subsequent mentions are unmarked and often incomplete -- e.g. family names are used instead of full names. We devised XXX two methods to account for unmarked entities: one that emphasizes XXX precision, and the other, recall. XXX

% Or NPP

The precision-oriented approach seeks to minimize the risk of a word getting incorrectly tagged XXX in the corpus. A short study of the ConLL annotation guidelines reveals that the words in the entities of interest to us all start with capital letter. According to this method XXX, all sentences that contain words that start with capital letter, but are not part of the anchor text of a link, XXX are discarded. The rationale behind this approach is that the sheer size of Wikipedia guarantees that we end up with a sizeable corpus even with such a strict policy. XXX

The recall-oriented method tries to associate unmarked entities with entities already identified on the same page. Only if the attempt fails is the sentence that contains the words discarded. This approach aims to generate more training sentences with as little loss of precision as possible. 

The algorithm maintains a list of entities already indentified on the page. The list includes
\begin{itemize}
\item The page title; % if it is in DBpedia
\item Title of redirect pages that target the current page; % TODO
\item Entities marked with links in the text thus far.
\end{itemize}

When an unmarked entity is encountered, the list is consulted to find an item that contains it in its entirety; i.e. all of its words and in the same order. If either exactly one such item is found, or the matching entities in the list all have the same NER tag, the unmarked entity is tagged accordingly. Otherwise the sentence is discarded.

Both approaches are evaluated in the next chapter.

\subsubsection{Tagging}

%TODO: merge with Entity Identification
We use DBpedia as 

Only sentences for whose entities the correct category could be obtained from DBpedia are added to the corpus; those that contain unknown entities are discarded. Sentences without any entities are retained as well, so that the corpus mirrors (XXX the distribution of entities in the corpus mirrors their distribution in Wikipedia?) the distribution of entities in Wikipedia as closely as possible; this is also in line with how the ConLL corpus is assembled. (XXX or is it)

\subsubsection{Exceptions}

Strictly speaking, our original assumption of equating Wikipedia articles with named entities is not valid: many pages describe common nouns (Book, Aircraft), numbers (1, 42), currencies (Euro, Dollar) or other concepts that fall outside the scope of NER. In this section, we describe the measures taken to avoid errors introduced by these false entities. We shall modify the two approaches -- precision and recall-oriented -- accordingly.

Proper entities that are not deemed NE under the ConLL scheme cause XXX little concern: they are either missing from DBpedia altogether, or we can map the classes they belong to to the NER category \texttt{0} (not an entity). This "ontological filtering" ensures that we need no adjustment XXX to our original method.

Links to number and common noun pages are handled differently by the two approaches. The precision-oriented method treats them similarly to links to unknown entities and discards the sentences in which they occur. The recall-oriented approach tries to distinguish them from links to entities so that otherwise valid training sentences can be retained XXX. The method is as follows XXX.
\begin{itemize}
\item Common nouns are filtered by POS category: links that contain no proper nouns are ignored.
\item Numbers behave more like proper nouns in that they can refer to entities, such as 737 to the Boeing 737. Therefore, links to number pages are filtered by the surface form of the page title.
\end{itemize}

Time expressions require special attention due to two reasons. First, Wikipedia has pages for years, months and concrete dates, therefore our algorithm might mistake them for entities. Second, as dates are made up of numbers and proper nouns, they can be mistaken for unmarked entities. To avoid these errors, we have create a set of regular expressions that recognize dates and time expressions and changed the recall-oriented method to not treat them as entities.

from \cite{Nothman:09}: Exceptions are made for common titlecase words, e.g. I, Mr., June, and sentence-initial words. 

% TODO: monetary, etc. units?

\subsubsection{Filtering}

There are many incomplete sentences in the Wikipedia text: image captions, enumerations items, contents of table cells, etc. On the one hand, these sentence fragments may prove to be of too low quality to be of any use in the traditional NER task. On the other hand, they could prove to be invaluable when training a named entity recognizer for user generated content. We have added a post-filtering step to recognize and label these fragments, so that users of the corpus can decide what to do with them. XXX

Manual inspection has found two conditions that can be used to detect fragments. A sentence is labelled as such if it either lacks a punctuation mark at the end or it contains no finite verbs. Our final corpus contains STAT full sentences and STAT fragments.
% TODO: Last sentence to evaluation? But then this whole subsection is too short.

% 4. Test sentence extraction?
%   a. unknown links, no unlinked names
%   b. might be good for quality evaluation / recursive tagging (next paper?)
% 5. teaching the original DBpedia categories?

\subsection{The DBpedia -- ConLL mapping}

% Introduction + entity -> class -> category.

The classes in DBpedia are organized into a type hierarchy, available as an OWL (CITE) ontology. The ontology contains the 320 most frequent categories of Wikipedia, arranged into a taxonomy under the base class \texttt{owl:Thing}. Most of the classes belong into the 5 largest sub-hierarchies (here named after their topmost classes XXX): \texttt{Agent} (which is further divided into \texttt{Person} and \texttt{Organisation}), \texttt{Event}, \texttt{Place}, \texttt{Species} and \texttt{Work}. The taxonomy is rather flat: the top level contains 44 classes and there are several nodes with a branching factor of 20.

It is not difficult to see the parallels XXX between the DBpedia sub-hierarchies \texttt{Person}, \texttt{Organisation} and \texttt{Place} and the ConLL NER categories \texttt{PER}, \texttt{ORG} and \texttt{LOC}. The fourth category, MISC is more elusive; according to the ConLL NER annotation guide (CITE?: http://www.cnts.ua.ac.be/conll2003/ner/annotation.txt), the sub-hierarchies \texttt{Event} and \texttt{Work} belong to this category, as well as various other class outside the main sub-hierarchies. 

While the correspondence described above holds for most classes in the XXX sub-hierarchies, there are some exceptions. For instance, the class \texttt{SportsLeague} is part of the \texttt{Organisation} sub-hierarchy, but in the ConLL corpus, sport leagues are tagged as MISC. Similarly, the class \texttt{SportsTeamSeason} is under \texttt{Event}, by which account it would be classified as MISC; however, ConLL does not recognize such entities. To account for these misclassification, as well as the miscellaneous classes outside the main hierarchies, we have introduced a mapping mechanism. We created a file of DBpedia class -- NER category mappings. Whenever an entity is evaluated, we look up its class, as well as the ancestors of its class, in the mapping, and assign to the entity the category of the class that matches it most closely -- i.e. the category of the entity's class, if it is in the list, or that of its closest ancestor. XXX!!! If no match is found, the entity is tagged with \texttt{0}. Since we take advantage of the inheritance hierarchy, the mapping list remains short: it contains only the root classes of the main sub-hierarchies, exceptions of the like XXX mentioned above and the various classes that belong to the MISC category according to the ConLL annotation guideline.

As of version 3.7, the DBpedia ontology allows multiple superclasses, making the hierarchy a directed acyclic graph. This introduces the problem of selecting the right superclass, and hence, ConLL mapping for classes with more than one parent. In version 3.7, the only such class is \textit{Library}, which can be traced back to both \textit{Place} and \textit{Organisation}. There are two ways to tackle this problem. The first is to follow the DBpedia guidelines and only retain the first parent. The second method is manually deciding the right NER mapping for the ambiguous XXX class and adding it to the mapping file. The first approach, unfortunately, already fails to assign the correct ConLL NER tag to our only example. The reason behind this failure is that multiple parents in an ontology show an inherent ambiguity in the class in question: it is entirely natural to think of a library as a location as well as a public organization. DBpedia's guidelines prefers Organisation; ConLL's LOC. Therefore, only the second, manual approach ensures correct tagging. XXX

The full mapping can be found in LINK Appendix A (XXX or not).

In Wikipedia the nationalities (e.g. American and Australian) links to the corresponding places (America and Australia, respectively). However, in CoNLL scheme these types of entities take parts of MISC category. XXX Postprocessing: list look-up (nationalities, adjective forms of person who live in the corresponding country); if the name is POS-tagged as adjective, then it is not a NE

%nem biztos, hogy ide kell
Link boundaries need to be adjusted, e.g. to remove excess punctuation.

\subsection{Remarks}

In this paper, we describe % not only ConLL? Do we need this?

\section{Creation of the Hungarian Corpus}

tokenizálás: built in-house, tailored for Hungarian, because of the specialities of Hungarian (e.g. period after years in date expressions)

ocamorph + hundisambig, a lemmatizálás miatt

a KR-ban nincs jelölve a proper noun külön

DBPedia--CoNLL mapping for Hungarian: az angol oldalak vannak megcímkézve --> csak azok a magyar oldalak vannak letöltve és feldolgozva, amik megvannak angolul is
	--> future work: kibővíteni azokkal a magyar cikkekkel is, amik nincsenek angolul

filtering: az igés szűrő itt nem lesz

most van: 102 millió szó a disambiguation pages-zel együtt
az angol: 1,7 milliárd

according to the Szeged NER guideline

a nyelv és népnevek magyarul nem NE-k, vagyis nem kell az annotálásukkal foglalkozni

a tulajdonnevekhez kötőjellel kapcsolódó köznevek kérdésesek (pl. SAP-szoftvercég, Matáv-csoport)

a tulajdonnevekből képzett szavak sem NE-k

% Good for middle-sized languages
% Inconsistent template names, esp. across languages
% Comparison of the Hungarian DBpedia vs English + mapping
% Not all entities are written w/ capital letters => we need lists.

\section{Evaluation}

% vs. ConLL / Szeged
% Corpus sizes, performance, tagging conventions

measuring Wikipedia's inconsistency using n-gram tag variation (\cite{Nothman:09})
ez jó mérőszám lehet a gold standard korpuszok összehasonlítására
használhatjuk fordítva is: ha egy adott nucleus ugyanolyan n-gram környezetben nagyon sokszor van X-ként taggelve, és kevésszer Y-ként, akkor az Y-okat is átcsinálhatnánk X-szé


\section{Conclusions and Future Work}

az eredeti DBPedia osztályokat is megtarthatnánk, hiszen nem mindig célravezető a CoNLL osztályok használata, mivel azok elég tág kategóriák, amikbe olyan dolgok is tartoznak, amik nagyon eltérőek is lehetnek

később majd kirakjuk a scripteket is, és akár újra és újra frissíthető lesz

\section{General Instructions}

Manuscripts must be in two-column format. Exceptions to the two-column format include the title, 
authors' names and complete addresses, which must be centered at the top of the first page, 
and any full-width figures or tables (see the guidelines in Subsection~\ref{ssec:first}). {\bf Type single-spaced}. 
Start all pages directly under the top margin. See the guide-lines later regarding formatting the first page. Do not number the pages.

\subsection{Electronically-available resources}

ACL2012 provides this description in \LaTeX2e (acl2012.tex) and PDF format (acl2012.pdf), along with the LATEX2e style file used to format it (acl2012.sty) and an ACL bibliography style (acl.bst). These files are all available at \url{http://www.acl2012.org}.  A Microsoft Word template file (acl2012.dot) is also available at the same URL. We strongly recommend the use of these style files, which have been appropriately tailored for the ACL2012 proceedings. If you have an option, we recommend that you use the \LaTeX2e version. \textbf{If you will be using the Microsoft Word template, we suggest that you anonymize your source file so that the pdf produced does not retain your identity.} This can be done by removing any personal information from your source
document properties.


\subsection{Format of Electronic Manuscript}
\label{sect:pdf}

For the production of the electronic manuscript you must use Adobe's
Portable Document Format (PDF). This format can be generated from
postscript files: on Linux/Unix systems, you can use {\tt ps2pdf} for this
purpose; under Microsoft Windows, you can use Adobe's Distiller, or
if you have {\tt cygwin} installed, you can use {\tt dvipdf} or
{\tt ps2pdf}.  Note
that some word processing programs generate PDF which may not include
all the necessary fonts (esp. tree diagrams, symbols). When you print
or create the PDF file, there is usually an option in your printer
setup to include none, all or just non-standard fonts.  Please make
sure that you select the option of including ALL the fonts.  {\em Before sending it, test your PDF by printing it from a computer different from the one where it was created}. Moreover,
some word processor may generate very large postscript/PDF files,
where each page is rendered as an image. Such images may reproduce
poorly.  In this case, try alternative ways to obtain the postscript
and/or PDF.  One way on some systems is to install a driver for a
postscript printer, send your document to the printer specifying
``Output to a file'', then convert the file to PDF.

Additionally, it is of utmost importance to specify the {\bf US-Letter format} (8.5in $\times$ 11in) when formatting the paper. When working with {\tt dvips}, for instance, one should specify {\tt -t letter}.

Print-outs of the PDF file on US-Letter paper should be identical to the
hardcopy version.  If you cannot meet the above requirements about the
production of your electronic submission, please contact the
publication chair above as soon as possible.


\subsection{Layout}
\label{ssec:layout}

Format manuscripts two columns to a page, in the manner these
instructions are formatted. The exact dimensions for a page on US-letter
paper are:

\begin{itemize}
\item Left and right margins: 1in
\item Top margin:1in
\item Bottom margin: 1in
\item Column width: 3.15in
\item Column height: 9in
\item Gap between columns: 0.2in
\end{itemize}

\noindent Papers should not be submitted on any other paper size. If you cannot meet the above requirements about the production of your electronic submission, please contact the publication chair above as soon as possible.

\subsection{Fonts}

For reasons of uniformity, Adobe's {\bf Times Roman} font should be
used. In \LaTeX2e{} this is accomplished by putting

\begin{quote}
\begin{verbatim}
\usepackage{times}
\usepackage{latexsym}
\end{verbatim}
\end{quote}
in the preamble. If Times Roman is unavailable, use {\bf Computer
  Modern Roman} (\LaTeX2e{}'s default).  Note that the latter is about
  10\% less dense than Adobe's Times Roman font.


\begin{table}[h]
\begin{center}
\begin{tabular}{|l|rl|}
\hline \bf Type of Text & \bf Font Size & \bf Style \\ \hline
paper title & 15 pt & bold \\
author names & 12 pt & bold \\
author affiliation & 12 pt & \\
the word ``Abstract'' & 12 pt & bold \\
section titles & 12 pt & bold \\
document text & 11 pt  &\\
captions & 11 pt & \\
abstract text & 10 pt & \\
bibliography & 10 pt & \\
footnotes & 9 pt & \\
\hline
\end{tabular}
\end{center}
\caption{\label{font-table} Font guide. }
\end{table}

\subsection{The First Page}
\label{ssec:first}

Center the title, author's name(s) and affiliation(s) across both
columns. Do not use footnotes for affiliations.  Do not include the
paper ID number assigned during the submission process.
Use the two-column format only when you begin the abstract.

{\bf Title}: Place the title centered at the top of the first page, in
a 15 point bold font.  (For a complete guide to font sizes and styles, see Table~\ref{font-table}.)
Long title should be typed on two lines without
a blank line intervening. Approximately, put the title at 1in from the
top of the page, followed by a blank line, then the author's names(s),
and the affiliation on the following line.  Do not use only initials
for given names (middle initials are allowed). Do not format surnames
in all capitals (e.g., ``Zhou,'' not ``ZHOU'').  The affiliation should
contain the author's complete address, and if possible an electronic
mail address. Leave about 0.75in between the affiliation and the body
of the first page. The title, author names and addresses should be completely identical to those entered to the electronic paper submission website in order to maintain the consistency of author information among all publications of the conference.

{\bf Abstract}: Type the abstract at the beginning of the first
column.  The width of the abstract text should be smaller than the
width of the columns for the text in the body of the paper by about
0.25in on each side.  Center the word {\bf Abstract} in a 12 point
bold font above the body of the abstract. The abstract should be a
concise summary of the general thesis and conclusions of the paper.
It should be no longer than 200 words. The abstract text should be in 10 point font.

{\bf Text}: Begin typing the main body of the text immediately after
the abstract, observing the two-column format as shown in
the present document. Do not include page numbers.

{\bf Indent} when starting a new paragraph. For reasons of uniformity,
use Adobe's {\bf Times Roman} fonts, with 11 points for text and
subsection headings, 12 points for section headings and 15 points for
the title.  If Times Roman is unavailable, use {\bf Computer Modern
  Roman} (\LaTeX2e's default; see section \ref{sect:pdf} above).
Note that the latter is about 10\% less dense than Adobe's Times Roman
font.

\subsection{Sections}

{\bf Headings}: Type and label section and subsection headings in the
style shown on the present document.  Use numbered sections (Arabic
numerals) in order to facilitate cross references. Number subsections
with the section number and the subsection number separated by a dot,
in Arabic numerals. Do not number subsubsections.

{\bf Citations}: Citations within the text appear
in parentheses as~\cite{Gusfield:97} or, if the author's name appears in
the text itself, as Gusfield~\shortcite{Gusfield:97}. Append lowercase letters to the year in cases of ambiguities. Treat double authors as in~\cite{Aho:72}, but write as in~\cite{Chandra:81} when more than two authors are involved. Collapse multiple citations as in~\cite{Gusfield:97,Aho:72}. Also refrain from using full citations as sentence constituents. We suggest that instead of
\begin{quote}
  ``\cite{Gusfield:97} showed that ...''
\end{quote}
you use
\begin{quote}
``Gusfield \shortcite{Gusfield:97}   showed that ...''
\end{quote}

If you are using the provided \LaTeX{} and Bib\TeX{} style files, you
can use the command \verb|\newcite| to get ``author (year)'' citations.

As reviewing will be double-blind, the submitted version of the papers should not include the
authors' names and affiliations. Furthermore, self-references that
reveal the author's identity, e.g.,
\begin{quote}
``We previously showed \cite{Gusfield:97} ...''
\end{quote}
should be avoided. Instead, use citations such as
\begin{quote}
``Gusfield \shortcite{Gusfield:97}
previously showed ... ''
\end{quote}

Please do not  use anonymous
citations and  do not include acknowledgements when submitting your papers. Papers that do not conform
to these requirements may be rejected without review.

\textbf{References}: Gather the full set of references together under
the heading {\bf References}; place the section before any Appendices,
unless they contain references. Arrange the references alphabetically
by first author, rather than by order of occurrence in the text.
Provide as complete a citation as possible, using a consistent format,
such as the one for {\em Computational Linguistics\/} or the one in the
{\em Publication Manual of the American
Psychological Association\/}~\cite{APA:83}.  Use of full names for
authors rather than initials is preferred.  A list of abbreviations
for common computer science journals can be found in the ACM
{\em Computing Reviews\/}~\cite{ACM:83}.

The \LaTeX{} and Bib\TeX{} style files provided roughly fit the
American Psychological Association format, allowing regular citations,
short citations and multiple citations as described above.

{\bf Appendices}: Appendices, if any, directly follow the text and the
references (but see above).  Letter them in sequence and provide an
informative title: {\bf Appendix A. Title of Appendix}.

\textbf{Acknowledgment} sections should go as a last section immediately
before the references. Do not number the acknowledgement section.

\subsection{Footnotes}

{\bf Footnotes}: Put footnotes at the bottom of the page. They may
be numbered or referred to by asterisks or other
symbols.\footnote{This is how a footnote should appear.} Footnotes
should be separated from the text by a line.\footnote{Note the
line separating the footnotes from the text.}  Footnotes should be in 9 point font.

\subsection{Graphics}

{\bf Illustrations}: Place figures, tables, and photographs in the
paper near where they are first discussed, rather than at the end, if
possible.  Wide illustrations may run across both columns and should be placed at
the top of a page. Color illustrations are discouraged, unless you have verified that
they will be understandable when printed in black ink.

{\bf Captions}: Provide a caption for every illustration; number each one
sequentially in the form:  ``Figure 1. Caption of the Figure.'' ``Table 1.
Caption of the Table.''  Type the captions of the figures and
tables below the body, using 10 point text.

\section{Translation of non-English Terms}

It is also advised to supplement non-English characters and terms
with appropriate transliterations and/or translations
since not all readers understand all such characters and terms.

Inline transliteration or translation can be represented in
the order of: original-form transliteration ``translation''.

\section{Length of Submission}
\label{sec:length}

Long papers may consist of up to eight (8) pages of content and an
additional two (2) pages of references, and short papers may consist
of up to four (4) pages of content and two (2) additional pages of
references.  Papers that do not conform to the specified length and
formatting requirements are subject to re-submission.

\section{Other Issues}
 
Those papers that had software and/or dataset submitted for the review process, should also submit it 
with the camera-ready paper. Besides, the software and/or dataset should not be anonymous. 

Please note that the publications of ACL2012 will be publicly available at ACL Anthology 
(http://aclweb.org/anthology-new/) on July 2nd, 2012, one week before the start of the conference. 
Since some of the authors may have plans to file patents related to their papers in the conference, 
we are sending this reminder that July 2nd, 2012 may be considered to be the official publication date, 
instead of the opening day of the conference.

%\section*{Acknowledgments}

%The authors are grateful to Attila Zséder and Gábor Recski for their respective work on Wikipedia parsing and {\tt hunner}.
%Do not number the acknowledgment section. Do not include this section when submitting your paper for review.

\begin{thebibliography}{}

\bibitem[\protect\citename{Nothman \bgroup et al.\egroup}2009]{Nothman:09}
\newblock 2009.
\newblock Analysing Wikipedia and Gold-Standard Corpora for NER Training.
\newblock In: {\em Proceedings of the 12th Conference of the European Chapter of the ACL}, pages 612--620.

\bibitem[\protect\citename{Richman and Schone}2008]{Richman:08}
Alexander E. Richman and Patrick Schone.
\newblock 2008.
\newblock Mining Wiki Resources for Multilingual Named Entity Recognition.
\newblock In: {\em Proceedings of ACL-08: HLT}, pages 1--9.

\bibitem[\protect\citename{Nothman \bgroup et al.\egroup}2008]{Nothman:08}
Joel Nothman, James R. Curran, and Tara Murphy.
\newblock 2008.
\newblock Transforming Wikipedia into Named Entity Training Data.
\newblock In: {\em Proceedings of the Australasian Language Technology Workshop}, Vol 6., pages 124--132.

\bibitem[\protect\citename{Kazama and Torisawa}2007]{Kazama:07}
Jun'ichi Kazama and Kentaro Torisawa.
\newblock 2007.
\newblock Exploiting Wikipedia as External Knowledge for Named Entity Recognition.
\newblock In: {\em Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning}, pages 698--707.

\bibitem[\protect\citename{Medelyan  \bgroup et al.\egroup}2009]{Medelyan:09}
Olena Medelyan, David Milne, Catherine Legg, and Ian H. Witten.
\newblock 2009.
\newblock Mining meaning from Wikipedia.
\newblock {\em International Journal of Human-Computer Studies}, 67: 716--754.

\bibitem[\protect\citename{Toral and Munoz}2006]{Toral:06}
A. Toral and R. Munoz.
\newblock 2006.
\newblock A proposal to automatically build and maintain gazetteers for Named Entity Recognition by using Wikipedia.
\newblock In: {\em EACL 2006}.

\bibitem[\protect\citename{Bunescu and Pasca}2006]{Bunescu:06}
B. Bunescu and M. Pasca.
\newblock 2006.
\newblock Using encyclopedic knowledge for named entity disambiguation.
\newblock In: {\em Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics}, pages 9--16.

\bibitem[\protect\citename{Cucerzan}2007]{Cucerzan:07}
S. Cucerzan.
\newblock 2007.
\newblock Large-scale named entity disambiguation based on Wikipedia data.
\newblock In: {\em Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning}.
\newblock Prague, Czech Republic, June 2007. pages 708--716.

\bibitem[\protect\citename{Nadeau  \bgroup et al.\egroup}2006]{Nadeau:06} 
David Nadeau, Peter D. Turney and Stan Matwin.
\newblock 2006.
\newblock Unsupervised named entity recognition: Generating gazetteers and resolving ambiguity. 
\newblock In: {\em Proceedings of the 19th Canadian Conference on Artificial Intelligence}, volume 4013 of {\em LNCS}, pages 266--277.

\bibitem[\protect\citename{Aho and Ullman}1972]{Aho:72}
Alfred~V. Aho and Jeffrey~D. Ullman.
\newblock 1972.
\newblock {\em The Theory of Parsing, Translation and Compiling}, volume~1.
\newblock Prentice-{Hall}, Englewood Cliffs, NJ.

\bibitem[\protect\citename{{American Psychological Association}}1983]{APA:83}
{American Psychological Association}.
\newblock 1983.
\newblock {\em Publications Manual}.
\newblock American Psychological Association, Washington, DC.

\bibitem[\protect\citename{{Association for Computing Machinery}}1983]{ACM:83}
{Association for Computing Machinery}.
\newblock 1983.
\newblock {\em Computing Reviews}, 24(11):503--512.

\bibitem[\protect\citename{Chandra \bgroup et al.\egroup }1981]{Chandra:81}
Ashok~K. Chandra, Dexter~C. Kozen, and Larry~J. Stockmeyer.
\newblock 1981.
\newblock Alternation.
\newblock {\em Journal of the Association for Computing Machinery},
  28(1):114--133.

\bibitem[\protect\citename{Gusfield}1997]{Gusfield:97}
Dan Gusfield.
\newblock 1997.
\newblock {\em Algorithms on Strings, Trees and Sequences}.
\newblock Cambridge University Press, Cambridge, UK.

\end{thebibliography}

\end{document}
